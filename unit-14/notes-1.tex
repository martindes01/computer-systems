\subsection{Introduction to Concurrency}

\subsubsection{Motivation}

A computer system typically has multiple users or user applications working independently.
The OS must protect the memory of one process from interference from another process.
It also interleaves the execution of processes to maximise resource utilisation and responsiveness of the system.
To do so, it must preserve the state of each process so that its execution may resume.

Concurrent execution of processes was originally intended solely for the maximisation of utilisation due to the great cost of computer systems, but nowadays it is intended to satisfy the expectations of users who wish to execute multiple tasks concurrently.

The problem is that these processes do not always work independently.
They may compete for access to resources, such as devices, files and data.
They may cooperate through messages, shared memory and files.
They may also be distributed such that millions of users are reading and updating information at the same time.
This is the case for social networking systems, banking and online shopping.

It is also necessary that applications can interleave multiple independent but potentially conflicting tasks.
An application with a graphical user interface (GUI) should not freeze when it is performing a time consuming task.
Similarly, a user of a banking system may not want to wait in a queue in order to perform a transaction.
Nevertheless, it is still necessary to maximise the efficiency of the system.

\subsubsection{Multiple Processes}

OS design is concerned with the management of processes and threads.
\begin{itemize}
  \item Multiprogramming --- multiple independent processes on a single processor
  \item Multiprocessing --- multiple processes on multiple processors
  \item Distributed processing --- multiple processes on multiple machines
\end{itemize}

Concurrency may be employed in the context of sharing resources amongst multiple applications, sharing resources between processes in a single application, or sharing resources between processes and threads of the OS itself.

\subsubsection{Key Terms}

\begin{description}
  \item[atomic operation] A function or action implemented as a sequence of one or more instructions that appears to be indivisible; that is, no other process can see an intermediate state or interrupt the operation.
  The sequence of instruction is guaranteed to execute as a group, or not execute at all, having no visible effect on the system state.
  Atomicity guarantees isolation from concurrent processes.
  \item[critical section] A section of code within a process that requires access to shared resources and that must not be executed while another process is in a corresponding section of code.
  \item[deadlock] A situation in which two or more processes are unable to proceed because each is waiting for one of the others to do something.
  \item[livelock] A situation in which two or more processes continuously change their states in response to changes in other processes without doing any useful work.
  \item[mutual exclusion] The requirement that when one process is in a critical section that accesses shared resources, no other process may be in a critical section that accesses any of those shared resources.
  \item[race condition] A situation in which multiple threads or processes read and write a shared data item and the final result depends on the relative timing of their execution.
  \item[starvation] A situation in which a runnable process is overlooked indefinitely by the scheduler; although it is able to proceed, it is never chosen.
\end{description}

A critical section must behave as an atomic operation.
Mutual exclusion occurs in a critical section.
A race condition must be managed by mutual exclusion.

\subsubsection{Principles of Concurrency}

Interleaving and overlapping can be viewed as examples on concurrent processing.
They both present the same problems.

In a uniprocessor system, the relative execution of processes cannot be predicted because it depends on the activities of the processes, how the OS handles interrupts and the scheduling policies of the OS.

\subsubsection{Difficulties of Concurrency}

Difficulties arise in the sharing of global resources, the optimal allocation of resources by the OS, and most importantly in the coordination of parallel and asynchronous processes so that they behave correctly.
They must produce the same results if they are executed concurrently as they would if they were executed consecutively.
The debugging of concurrent programming errors is difficult because observed behaviour is non-deterministic (dependent upon timings of other processes on the machine).
It is therefore difficult to identify and reproduce.

\subsection{OS Concerns and Process Interaction}

In order to manage the issues raised by concurrency, the OS must be able to keep track of various processes, allocate and deallocate resources for each active process, protect the data and physical resources of each process from interference by other processes, and ensure that the processes and outputs are independent of `processing speed' (the timing of completion of different operations).

\begin{table}[htp]
  \centering
  \caption*{Relationships between concurrent processes.}
  \begin{tabular}{p{3cm}p{2cm}p{4cm}p{4cm}}
    \toprule
    Degree of awareness & Relationship & Influence of one process on the other & Potential control problems \\
    \midrule
    Processes unaware of each other & Competition & \begin{itemize}
      \item Results of one process independent of the other
      \item Timing of processes may be affected
    \end{itemize} & \begin{itemize}
      \item Mutual exclusion
      \item Deadlock (renewable resource)
      \item Starvation
    \end{itemize} \\
    Processes indirectly aware of each other (e.g.\ shared object) & Cooperation by sharing & \begin{itemize}
      \item Results of one process may depend on information obtained by other
      \item Timing of processes may be affected
    \end{itemize} & \begin{itemize}
      \item Mutual exclusion
      \item Deadlock (renewable resource)
      \item Starvation
      \item Data coherence
    \end{itemize} \\
    Processes directly aware of each other (have communication primitives available to them) & Cooperation by communication & \begin{itemize}
      \item Results of one process may depend on information obtained from other
      \item Timing of processes may be affected
    \end{itemize} & \begin{itemize}
      \item Deadlock (consumable resource)
      \item Starvation
    \end{itemize} \\
    \bottomrule
  \end{tabular}
\end{table}

\subsection{Resource Competition}

Concurrent processes come into conflict when they are competing for use of the same resource, such as I/O devices, memory, processor time and the clock.
In the case of competing processes, three control problems must be faced.
\begin{itemize}
  \item Mutual exclusion --- to ensure correct behaviour
  \item Deadlock
  \item Starvation
\end{itemize}

A race condition occurs when multiple processes or threads read and write shared data items.
The processes ``race'' to perform their read/write actions.
The final result depends on the order of execution.
The ``loser'' of the race is the process that performs the last update and determines the final value of the shared data item.

Race conditions can occur due to
\begin{itemize}
  \item order of execution --- whenever the state of a shared resource depends on the precise order of execution of the processes,
  \item scheduling --- context switches at arbitrary times during execution, or
  \item outdated information --- processes or threads operating with stale or dirty copies of memory values in registers or local variables.
\end{itemize}

\subsection{Critical Section Problem}

\subsubsection{Critical Section}

In order to avoid race conditions, it is necessary to control the concurrent execution of critical sections.
This is achieved through strict serialisation, or mutual exclusion, causing the critical sections to behave as atomic operations.

An entry protocol is executed before a critical section.
The process requests permission to enter the critical section.
The process may have to wait for entry to be granted.
It must communicate that it has entered the critical section.

A process is able to complete the execution of its critical section, even if it is preempted or interrupted.
An exit protocol is executed after a critical section.
The process communicates to other processes that it has left the critical section.

It is important that the scope and length of critical sections is kept as small as possible.
Large critical sections can be detrimental to the efficiency and throughput of a system.

\subsubsection{Deadlock and Starvation}

Enforcing mutual exclusion creates the problems of deadlocks --- processes waiting forever for each other to free resources --- and starvation --- a process waiting forever to be granted entry to its critical section.
Implementations of mutual exclusion must account for these problems.
Critical sections must be as small as possible and processes must spend as little time as possible in a critical section.

\subsubsection{Requirements for Solutions to the Problem}

\begin{enumerate}
  \item Serialisation of access
  \begin{itemize}
    \item Only one process at a time is allowed in the critical section for a resource
  \end{itemize}
  \item Bounded waiting (no starvation)
  \begin{itemize}
    \item A process waiting to enter a critical section must be guaranteed entry within some defined limited waiting time
    \item The scheduling algorithm must guarantee that the process is eventually scheduled
  \end{itemize}
  \item Progress (liveness, no deadlock)
  \begin{itemize}
    \item A process that halts in its non-critical section must do so without interfering with other processes waiting to enter their critical section
    \item Only processes currently waiting to enter their critical section are involved in the selection of the one process that may enter
    \item A process remains inside its critical section for a finite time only
  \end{itemize}
\end{enumerate}

\begin{enumerate}
  \item Software solutions
  \begin{itemize}
    \item Shared lock variables (busy-waiting)
    \item Polling and spinning or strict alternation
  \end{itemize}
  \item Hardware solutions
  \begin{itemize}
    \item Disabling interrupts
    \item Special instructions
  \end{itemize}
  \item Higher-level OS constructs
  \begin{itemize}
    \item Semaphores, monitors or message passing
  \end{itemize}
\end{enumerate}

\subsection{Software Solutions}

\subsubsection{Lock Variables}

Critical sections must be protected by some form of `lock'.
A lock is a shared data item.
Processes must acquire a lock before entering a critical section, and release the lock when exiting the critical section.
A lock is also known as a `mutex'.

A two state lock may be implemented as a shared variable.
A process will wait while the lock is true, then when it is false, set the lock to true and execute its critical actions.
When its critical section is complete, it will set the lock to false.
However, in this implementation, the lock itself is a shared resource and a race condition may occur on it.
Atomic instructions must be used for a shared lock.

\subsubsection{Busy-Waiting (Polling and Spinning)}

In this solution, a process continuously evaluates whether a lock has become available.
The lock is represented by a data item held in shared memory.
This causes the process to consume CPU cycles without any progress.
A process busy-waiting may prevent another process holding the lock from executing and completing its critical section and from releasing the lock.

\subsubsection{Busy-Waiting (Strict Alternation)}

This solution imposes a strict alternation between two processes; a process waits for its turn.
A token is used as a shared variable.
This is usually a process ID set by the previous process that indicates which process is next to enter.
A process busy-waits until the token is its own process ID.
When the process exits the critical section, it sets the token to the next process ID.

This solution guarantees mutual exclusion because there is no longer a race condition on the lock.
However, there is still a problem of liveness and progression since multiple processes depend on the change of the token.
If one of the processes is delayed in its non-critical section, it cannot enter its critical section when it is its turn, and other processes will be blocked.

\subsection{Hardware Solutions}

\subsubsection{Disabling Interrupts}

In uniprocessor systems, concurrent processes cannot be overlapped, only interleaved.
Thus, disabling interrupts guarantees mutual exclusion, but significantly reduces the efficiency of execution.
This approach does not work on a multiprocessor system.

\subsubsection{Special Hardware Instructions}

These are applicable to any number of processes on either uniprocessor or multiprocessor systems sharing a main memory.
They are simple and easy to verify and can be used to support multiple critical sections.
However, they use busy-waiting and may still cause starvation and deadlocks.

\subsection{Abstractions}

Some systems may execute critical sections regardless, then detect whether problems have occurred.
If so, the changes are undone.
Sometimes such problems do not occur very often, and doing a lot of work to fix a problem when it occurs is overall more efficient than doing a little work every time to avoid the problem.
This is used in database systems.

In other cases, it may be acceptable to have errors caused by concurrency.

Many systems, such as databases and Java, implement their own concurrent mechanisms that work correctly and efficiently, and provide abstractions of these mechanisms to programmers.
Therefore, it is often not necessary to worry about deadlocks in practice.
